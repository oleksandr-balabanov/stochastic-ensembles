This job can be monitored from: https://scruffy.c3se.chalmers.se/d/alvis-job/alvis-job?var-jobid=804712&from=1676290730000
################################################################################
Running slurm job
################################################################################
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (564) bind mounts
INFO:    underlay of /usr/share/lmod/lmod required more than 50 (92) bind mounts
SEED:  73
--------------TRUE POSTERIOR-------------------------
sample input.weight torch.Size([10, 2])
sample input.bias torch.Size([10])
sample layers.0.weight torch.Size([10, 10])
sample layers.0.bias torch.Size([10])
sample output.weight torch.Size([2, 10])
sample output.bias torch.Size([2])
sample data torch.Size([2000])
sample obs torch.Size([2000])
torch.Size([8000, 10])
torch.Size([8000, 10, 2])
torch.Size([8000, 10])
torch.Size([8000, 10, 10])
torch.Size([8000, 2])
torch.Size([8000, 2, 10])
Saving HMC models at /mimer/NOBACKUP/groups/snic2022-22-448/CVPR_revision/toy_olebal_silu/3/HMC/model_HMC_chains_4_s_2000_w_2000_ss_1.json
{'input.bias': OrderedDict([('n_eff', tensor([2143.8845, 1912.8942, 2120.7627, 2190.5769, 1855.5312, 2143.0151,
        1896.7960, 1730.6615, 2131.9189, 2158.2905], device='cuda:0')), ('r_hat', tensor([1.0020, 1.0015, 1.0024, 0.9998, 1.0051, 1.0046, 1.0032, 1.0012, 1.0013,
        1.0025], device='cuda:0'))]), 'input.weight': OrderedDict([('n_eff', tensor([[1247.7886, 1866.4802],
        [1017.5099, 1818.4011],
        [1034.7036, 2292.8179],
        [1382.4659, 1148.7588],
        [ 982.9866, 1624.4431],
        [1329.7335, 2317.4895],
        [1152.3512, 1478.1302],
        [ 958.7719, 1940.8031],
        [1247.1692, 2020.7749],
        [1254.8507, 1827.4265]], device='cuda:0')), ('r_hat', tensor([[1.0022, 1.0032],
        [1.0060, 1.0013],
        [1.0003, 1.0019],
        [1.0024, 1.0043],
        [1.0018, 1.0042],
        [1.0019, 1.0020],
        [1.0024, 1.0000],
        [1.0017, 1.0011],
        [1.0038, 1.0007],
        [1.0032, 1.0017]], device='cuda:0'))]), 'layers.0.bias': OrderedDict([('n_eff', tensor([4261.1431, 4324.9219, 4567.0078, 5533.4741, 6675.9438, 5291.1211,
        5000.2202, 5323.1689, 5282.8735, 4165.5044], device='cuda:0')), ('r_hat', tensor([1.0000, 1.0002, 1.0005, 1.0003, 1.0004, 1.0002, 1.0000, 0.9999, 1.0013,
        1.0001], device='cuda:0'))]), 'layers.0.weight': OrderedDict([('n_eff', tensor([[3872.5574, 2999.5486, 4401.2788, 3648.2129, 3536.6052, 4373.1880,
         4401.6216, 4613.5244, 4781.5142, 4716.4385],
        [3755.4880, 4234.0552, 3695.3218, 4481.4023, 2580.6199, 4491.4131,
         3652.9409, 3653.0166, 4025.3252, 4825.2612],
        [4180.5669, 4387.5659, 4383.9072, 4329.1245, 4106.8765, 4629.0776,
         4456.2075, 4999.0122, 4382.8530, 4586.9272],
        [4369.5737, 3415.5769, 4000.1802, 4945.6514, 4056.0132, 5033.7778,
         4338.0366, 4846.4561, 4545.9595, 4949.3135],
        [5305.3257, 4428.8027, 5287.5015, 3818.1738, 4523.2515, 4093.1521,
         4051.7559, 4323.5210, 3869.3682, 3500.1426],
        [4381.8823, 4779.7222, 4709.5737, 4766.2119, 4117.0415, 4879.6304,
         4341.9712, 3949.8777, 5798.9624, 5424.6367],
        [5404.4077, 4605.2788, 4014.7556, 3945.5291, 4721.3638, 6004.8496,
         5105.8159, 4800.0630, 3644.2112, 3346.8452],
        [4196.6074, 3598.6238, 3505.7148, 3437.3765, 3642.4934, 4409.6802,
         2652.0393, 3937.9946, 4145.1719, 3543.3618],
        [4337.4785, 5087.3887, 3704.5947, 5037.2119, 4730.1919, 4520.8101,
         4411.3218, 3914.2766, 4442.1729, 4663.1567],
        [4120.7607, 4013.1721, 4085.7078, 3598.1902, 4221.8335, 4540.7817,
         4012.0610, 4473.7925, 4214.6626, 4738.2725]], device='cuda:0')), ('r_hat', tensor([[1.0011, 1.0000, 1.0008, 1.0007, 0.9998, 1.0008, 1.0003, 1.0002, 1.0000,
         1.0004],
        [1.0002, 0.9999, 1.0014, 1.0006, 1.0014, 1.0008, 1.0007, 1.0004, 1.0009,
         0.9998],
        [0.9998, 1.0002, 0.9999, 1.0002, 1.0004, 0.9997, 1.0005, 1.0008, 1.0005,
         1.0005],
        [1.0001, 1.0005, 1.0009, 1.0004, 1.0003, 1.0003, 1.0007, 0.9997, 1.0003,
         1.0007],
        [1.0006, 1.0005, 1.0009, 1.0009, 1.0005, 1.0026, 1.0007, 1.0007, 1.0004,
         1.0015],
        [0.9998, 1.0005, 1.0000, 0.9999, 1.0004, 1.0002, 1.0000, 0.9997, 0.9996,
         1.0010],
        [1.0001, 1.0000, 1.0006, 1.0002, 1.0003, 1.0002, 0.9999, 1.0002, 1.0009,
         1.0012],
        [1.0007, 1.0000, 1.0013, 1.0008, 1.0008, 1.0008, 1.0011, 1.0006, 1.0005,
         1.0007],
        [0.9999, 1.0004, 1.0004, 1.0001, 1.0002, 1.0018, 1.0002, 1.0011, 1.0006,
         1.0006],
        [1.0013, 1.0006, 1.0008, 1.0002, 1.0003, 1.0009, 1.0005, 0.9996, 1.0014,
         1.0001]], device='cuda:0'))]), 'output.bias': OrderedDict([('n_eff', tensor([10388.3496,  9764.5615], device='cuda:0')), ('r_hat', tensor([0.9997, 0.9995], device='cuda:0'))]), 'output.weight': OrderedDict([('n_eff', tensor([[ 715.5679,  632.9534,  718.5715,  703.8781,  753.9913, 1140.2102,
          824.4185,  582.4417,  793.6389,  576.0402],
        [ 710.5532,  641.3785,  711.2023,  712.0539,  724.9578, 1096.6447,
          859.0912,  587.3146,  785.0966,  605.5501]], device='cuda:0')), ('r_hat', tensor([[1.0063, 1.0076, 1.0039, 1.0074, 1.0023, 1.0014, 1.0026, 1.0028, 1.0089,
         1.0029],
        [1.0077, 1.0074, 1.0037, 1.0076, 1.0018, 1.0017, 1.0021, 1.0033, 1.0097,
         1.0027]], device='cuda:0'))]), 'divergences': {'chain 0': [1383, 1947, 1955], 'chain 1': [148, 1194, 1362, 1422, 1803], 'chain 2': [477, 700, 982, 1180, 1697], 'chain 3': [135, 138, 337, 338, 706]}, 'acceptance rate': {'chain 0': 1.0, 'chain 1': 1.0, 'chain 2': 0.9995, 'chain 3': 1.0}}
[W CudaIPCTypes.cpp:15] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]
