This job can be monitored from: https://scruffy.c3se.chalmers.se/d/alvis-job/alvis-job?var-jobid=804711&from=1676290730000
################################################################################
Running slurm job
################################################################################
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (564) bind mounts
INFO:    underlay of /usr/share/lmod/lmod required more than 50 (92) bind mounts
SEED:  841
--------------TRUE POSTERIOR-------------------------
sample input.weight torch.Size([10, 2])
sample input.bias torch.Size([10])
sample layers.0.weight torch.Size([10, 10])
sample layers.0.bias torch.Size([10])
sample output.weight torch.Size([2, 10])
sample output.bias torch.Size([2])
sample data torch.Size([2000])
sample obs torch.Size([2000])
torch.Size([8000, 10])
torch.Size([8000, 10, 2])
torch.Size([8000, 10])
torch.Size([8000, 10, 10])
torch.Size([8000, 2])
torch.Size([8000, 2, 10])
Saving HMC models at /mimer/NOBACKUP/groups/snic2022-22-448/CVPR_revision/toy_olebal_silu/2/HMC/model_HMC_chains_4_s_2000_w_2000_ss_1.json
{'input.bias': OrderedDict([('n_eff', tensor([ 962.8248, 1173.7170,  991.2737, 1073.7079,  903.4833, 1167.4061,
        1345.1039, 1317.2517,  670.5352, 1068.5231], device='cuda:0')), ('r_hat', tensor([1.0085, 1.0023, 1.0016, 1.0063, 1.0062, 1.0003, 1.0006, 1.0041, 1.0032,
        1.0027], device='cuda:0'))]), 'input.weight': OrderedDict([('n_eff', tensor([[ 536.9435,  928.7604],
        [ 470.5219,  882.9661],
        [ 449.6688,  444.9611],
        [ 572.9364, 1074.4615],
        [ 512.1205,  560.5186],
        [ 470.1298, 1021.7958],
        [ 602.4853, 1084.7800],
        [ 777.1191, 1132.0011],
        [ 672.8398,  812.4991],
        [ 723.7890, 1091.5813]], device='cuda:0')), ('r_hat', tensor([[1.0081, 1.0050],
        [1.0137, 1.0039],
        [1.0103, 1.0166],
        [1.0049, 1.0060],
        [1.0054, 1.0043],
        [1.0062, 1.0041],
        [1.0085, 1.0022],
        [1.0023, 1.0067],
        [1.0026, 1.0043],
        [1.0100, 1.0055]], device='cuda:0'))]), 'layers.0.bias': OrderedDict([('n_eff', tensor([2390.5298, 1964.9525, 2330.4146, 3466.5725, 1703.9674, 2713.2112,
        1653.9050, 2279.2534, 2690.9265, 2581.6106], device='cuda:0')), ('r_hat', tensor([1.0020, 1.0042, 0.9998, 1.0003, 1.0009, 1.0001, 1.0026, 1.0003, 1.0007,
        1.0021], device='cuda:0'))]), 'layers.0.weight': OrderedDict([('n_eff', tensor([[1944.3949, 2420.3647, 2094.1538, 1744.7798, 1779.0404, 1488.1276,
         1659.4775, 2612.5840, 1983.3335, 2342.2649],
        [ 823.7505, 1712.0999,  608.7151, 2409.8367,  983.3587, 1354.3744,
         1800.3964, 1519.2631, 1464.7991, 1086.7012],
        [2582.6787, 2202.6584, 1983.6569, 1621.0027, 1514.1963, 2183.7427,
         1815.6732, 2845.8467, 1811.8406, 1647.0325],
        [1599.2441, 1355.6654, 1472.7201, 2348.8958, 1571.2703, 1838.5507,
         2331.8140, 1930.6525, 1190.2474, 1099.1384],
        [2324.3198, 1526.9844, 1514.2717, 1663.7990,  946.4288, 1848.1937,
         1511.7828, 1311.9559, 1683.5872, 1874.5500],
        [1515.6301, 1859.3865, 2239.8970, 1504.4686, 1439.2853, 1756.6462,
         1878.1705, 1472.1666, 1439.9225, 2056.4209],
        [1093.1796, 1553.4535, 1409.9672, 1311.4093, 1788.0088,  851.8514,
         2147.1057, 1979.0992, 1172.5778, 1833.7457],
        [1825.1805, 1591.9064, 1674.0120, 1572.6273, 2089.8296, 2035.2228,
         1993.6322, 1560.3967, 1649.6383, 1758.9038],
        [1600.2186, 1934.7965, 1403.4604, 1526.5531, 1766.1245, 2434.5210,
         1691.0317, 1566.4727, 1066.5305, 1874.3088],
        [1724.4232, 1553.1440, 1276.5229, 2612.5425, 1575.2704, 1367.4791,
         2175.3662, 1964.4309, 1971.1683, 2002.9067]], device='cuda:0')), ('r_hat', tensor([[1.0008, 1.0023, 1.0006, 1.0021, 1.0006, 1.0025, 1.0007, 0.9999, 1.0016,
         1.0025],
        [1.0031, 1.0019, 1.0073, 1.0013, 1.0078, 1.0015, 1.0025, 1.0001, 1.0013,
         1.0072],
        [1.0007, 1.0053, 1.0008, 1.0011, 1.0013, 1.0003, 1.0025, 1.0015, 1.0017,
         1.0016],
        [1.0023, 1.0026, 1.0015, 1.0021, 1.0004, 1.0008, 1.0015, 1.0007, 1.0066,
         1.0023],
        [1.0000, 1.0019, 1.0010, 1.0026, 1.0057, 1.0024, 1.0015, 1.0025, 1.0009,
         1.0008],
        [1.0022, 1.0015, 1.0013, 1.0030, 1.0013, 1.0008, 1.0020, 1.0006, 1.0020,
         1.0015],
        [1.0026, 1.0045, 1.0055, 1.0026, 1.0005, 1.0021, 1.0010, 1.0012, 1.0037,
         1.0017],
        [1.0023, 1.0018, 1.0013, 1.0043, 1.0009, 1.0006, 1.0022, 1.0027, 1.0044,
         1.0025],
        [1.0024, 1.0018, 1.0023, 1.0023, 1.0029, 1.0015, 1.0016, 1.0028, 1.0038,
         1.0012],
        [1.0017, 1.0046, 1.0046, 1.0011, 1.0016, 1.0019, 1.0002, 1.0016, 1.0034,
         1.0022]], device='cuda:0'))]), 'output.bias': OrderedDict([('n_eff', tensor([3771.2839, 3257.6619], device='cuda:0')), ('r_hat', tensor([1.0005, 1.0019], device='cuda:0'))]), 'output.weight': OrderedDict([('n_eff', tensor([[447.8487, 272.8813, 587.0018, 468.3867, 315.8494, 397.3035, 405.9917,
         421.9753, 344.2113, 385.0306],
        [462.1487, 294.8815, 589.2642, 463.0070, 363.0414, 409.2397, 417.8202,
         402.6974, 367.7259, 427.7121]], device='cuda:0')), ('r_hat', tensor([[1.0087, 1.0124, 1.0039, 1.0094, 1.0169, 1.0123, 1.0063, 1.0094, 1.0223,
         1.0120],
        [1.0090, 1.0129, 1.0047, 1.0097, 1.0154, 1.0129, 1.0069, 1.0122, 1.0212,
         1.0078]], device='cuda:0'))]), 'divergences': {'chain 0': [142, 220, 221, 243, 339, 371, 550, 616, 668, 707, 775, 792, 793, 804, 837, 970, 1019, 1076, 1126, 1164, 1412, 1512, 1588, 1594, 1620, 1758, 1759, 1760, 1761, 1762, 1781, 1782, 1783, 1785, 1788, 1793, 1899, 1933, 1937, 1938, 1949], 'chain 1': [5, 6, 47, 56, 60, 62, 66, 74, 102, 127, 170, 171, 176, 179, 185, 217, 226, 253, 257, 286, 287, 289, 300, 309, 310, 313, 314, 315, 334, 357, 401, 405, 442, 476, 512, 556, 560, 561, 586, 596, 615, 616, 619, 626, 639, 652, 654, 656, 660, 662, 699, 705, 711, 720, 740, 762, 782, 787, 788, 789, 790, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 808, 809, 810, 811, 812, 813, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 827, 828, 829, 831, 833, 835, 836, 837, 838, 839, 840, 841, 843, 845, 847, 848, 849, 850, 851, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 883, 884, 885, 886, 887, 888, 889, 890, 891, 893, 894, 895, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 909, 910, 911, 913, 935, 937, 938, 957, 971, 972, 976, 1010, 1025, 1082, 1123, 1128, 1180, 1194, 1269, 1378, 1407, 1420, 1421, 1426, 1430, 1446, 1474, 1487, 1513, 1517, 1544, 1555, 1601, 1614, 1623, 1624, 1628, 1629, 1643, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1738, 1764, 1796, 1797, 1820, 1865, 1880, 1888, 1889, 1933, 1974], 'chain 2': [212, 352, 369, 549, 551, 1263, 1692, 1976], 'chain 3': [5, 65, 241, 254, 255, 256, 285, 308, 317, 341, 490, 521, 536, 600, 650, 697, 723, 830, 868, 921, 922, 968, 1077, 1217, 1352, 1359, 1451, 1505, 1512, 1576, 1577, 1585, 1707, 1826, 1975]}, 'acceptance rate': {'chain 0': 1.0, 'chain 1': 0.98, 'chain 2': 1.0, 'chain 3': 1.0}}
[W CudaIPCTypes.cpp:15] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]
