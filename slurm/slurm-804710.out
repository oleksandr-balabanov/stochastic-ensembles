This job can be monitored from: https://scruffy.c3se.chalmers.se/d/alvis-job/alvis-job?var-jobid=804710&from=1676290730000
################################################################################
Running slurm job
################################################################################
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (564) bind mounts
INFO:    underlay of /usr/share/lmod/lmod required more than 50 (92) bind mounts
SEED:  256
--------------TRUE POSTERIOR-------------------------
sample input.weight torch.Size([10, 2])
sample input.bias torch.Size([10])
sample layers.0.weight torch.Size([10, 10])
sample layers.0.bias torch.Size([10])
sample output.weight torch.Size([2, 10])
sample output.bias torch.Size([2])
sample data torch.Size([2000])
sample obs torch.Size([2000])
torch.Size([8000, 10])
torch.Size([8000, 10, 2])
torch.Size([8000, 10])
torch.Size([8000, 10, 10])
torch.Size([8000, 2])
torch.Size([8000, 2, 10])
Saving HMC models at /mimer/NOBACKUP/groups/snic2022-22-448/CVPR_revision/toy_olebal_silu/1/HMC/model_HMC_chains_4_s_2000_w_2000_ss_1.json
{'input.bias': OrderedDict([('n_eff', tensor([2366.1960, 2231.4924, 2351.7874, 2348.9973, 1942.6860, 2456.6812,
        2109.4058, 1972.3976, 2167.2424, 2236.3452], device='cuda:0')), ('r_hat', tensor([1.0021, 1.0023, 1.0004, 1.0003, 1.0020, 1.0032, 1.0020, 1.0004, 1.0006,
        1.0011], device='cuda:0'))]), 'input.weight': OrderedDict([('n_eff', tensor([[1179.2913, 1569.2557],
        [1249.4463, 1213.7355],
        [ 975.2130, 1435.0350],
        [1120.1050, 1591.5731],
        [1153.6207, 1269.6276],
        [1021.8076, 1501.9617],
        [1011.0969, 1132.2432],
        [ 800.0327, 1457.8378],
        [1203.2527, 1246.4594],
        [ 887.0596, 1510.8584]], device='cuda:0')), ('r_hat', tensor([[1.0023, 1.0005],
        [1.0022, 1.0040],
        [1.0019, 1.0017],
        [1.0003, 1.0041],
        [1.0003, 1.0017],
        [1.0078, 1.0036],
        [1.0041, 1.0024],
        [1.0029, 1.0012],
        [1.0005, 1.0010],
        [1.0048, 1.0011]], device='cuda:0'))]), 'layers.0.bias': OrderedDict([('n_eff', tensor([3771.7483, 4045.2131, 3663.4199, 4216.7563, 4439.7681, 4362.3628,
        3661.2808, 4049.8972, 4592.5293, 4541.5859], device='cuda:0')), ('r_hat', tensor([1.0006, 1.0001, 1.0000, 0.9998, 0.9999, 1.0000, 1.0009, 1.0005, 1.0013,
        1.0000], device='cuda:0'))]), 'layers.0.weight': OrderedDict([('n_eff', tensor([[4094.3699, 3965.3328, 3920.9639, 3595.8101, 3535.3992, 4114.7769,
         2883.3542, 3048.3203, 3177.3896, 3471.7651],
        [3685.9558, 3605.0271, 3142.4258, 3404.9976, 3459.5100, 3746.0247,
         3360.1760, 4159.8477, 3237.8831, 3666.7241],
        [3403.2983, 3498.3799, 4472.7915, 3832.6150, 4253.1812, 4589.2754,
         2831.5728, 3743.7991, 4008.3613, 3701.7112],
        [4793.3657, 4704.1338, 3795.7249, 3294.6287, 3518.7683, 3691.3689,
         3757.4819, 3693.7629, 3028.3833, 3230.9253],
        [4074.0308, 3305.1135, 4326.6426, 3998.3943, 3996.6855, 4092.7380,
         2657.5637, 4191.7559, 4602.7573, 3776.2090],
        [4018.4937, 3911.7690, 2752.8687, 3329.9307, 4105.2261, 4234.7920,
         3289.5483, 4037.6543, 4189.0859, 2927.1475],
        [3588.5601, 3589.0818, 3006.3467, 3626.3857, 3143.3816, 3866.1909,
         3606.8398, 3212.4775, 2895.5283, 3356.2952],
        [4295.5830, 3477.6968, 3934.2976, 3350.4087, 3359.9653, 3720.7766,
         3294.5405, 2854.1794, 3381.2102, 3566.2119],
        [3646.5645, 3136.9526, 5044.3071, 3534.4502, 3851.0486, 2993.8579,
         4059.8196, 3715.1450, 4614.0908, 3734.4919],
        [4176.9316, 4071.5242, 3950.4292, 3822.7517, 3621.9956, 3841.3511,
         4430.2412, 3659.6545, 4605.2847, 3326.1313]], device='cuda:0')), ('r_hat', tensor([[1.0009, 1.0015, 1.0003, 1.0004, 1.0006, 1.0002, 1.0016, 1.0001, 1.0004,
         1.0012],
        [1.0006, 1.0001, 1.0002, 0.9999, 1.0003, 1.0001, 1.0016, 1.0002, 1.0001,
         1.0004],
        [1.0011, 1.0013, 1.0003, 1.0002, 1.0000, 0.9999, 1.0002, 1.0019, 1.0013,
         1.0016],
        [0.9997, 1.0004, 1.0008, 1.0003, 1.0000, 1.0003, 1.0007, 0.9998, 1.0007,
         1.0005],
        [0.9998, 1.0006, 0.9999, 1.0006, 1.0004, 1.0007, 1.0009, 0.9999, 1.0006,
         1.0004],
        [1.0006, 1.0013, 1.0022, 1.0002, 1.0002, 0.9996, 0.9996, 1.0013, 0.9997,
         1.0005],
        [1.0008, 1.0004, 1.0004, 1.0021, 1.0039, 1.0010, 1.0008, 1.0010, 1.0016,
         1.0008],
        [0.9999, 1.0003, 1.0001, 1.0010, 1.0003, 1.0007, 1.0022, 1.0009, 0.9999,
         1.0002],
        [1.0005, 1.0007, 1.0005, 1.0000, 1.0005, 1.0012, 1.0001, 1.0017, 1.0009,
         1.0005],
        [1.0003, 1.0006, 1.0011, 1.0003, 1.0007, 1.0002, 1.0010, 1.0005, 1.0002,
         1.0001]], device='cuda:0'))]), 'output.bias': OrderedDict([('n_eff', tensor([7837.9126, 8401.2441], device='cuda:0')), ('r_hat', tensor([0.9998, 1.0001], device='cuda:0'))]), 'output.weight': OrderedDict([('n_eff', tensor([[725.7979, 815.6108, 801.4547, 785.6379, 760.2673, 739.5254, 420.4821,
         702.0594, 882.8121, 995.0996],
        [724.8275, 834.3240, 809.5920, 758.6638, 771.2906, 710.7097, 468.4021,
         730.1028, 904.3311, 925.8663]], device='cuda:0')), ('r_hat', tensor([[1.0080, 1.0011, 1.0030, 1.0050, 1.0031, 1.0060, 1.0137, 1.0006, 1.0056,
         1.0020],
        [1.0085, 1.0012, 1.0032, 1.0051, 1.0036, 1.0070, 1.0129, 1.0000, 1.0046,
         1.0015]], device='cuda:0'))]), 'divergences': {'chain 0': [854, 1295, 1618, 1920, 1975, 1977], 'chain 1': [118, 1065, 1066, 1067, 1973, 1974, 1975], 'chain 2': [598, 714], 'chain 3': [186, 195, 421, 1405, 1479, 1724]}, 'acceptance rate': {'chain 0': 0.9995, 'chain 1': 1.0, 'chain 2': 1.0, 'chain 3': 1.0}}
[W CudaIPCTypes.cpp:15] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]
